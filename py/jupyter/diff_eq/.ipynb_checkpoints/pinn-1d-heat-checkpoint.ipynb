{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9a4b21-d8d9-46af-bf6f-77c1184a046a",
   "metadata": {},
   "source": [
    "# Physics-Informed Neural Networks (PINNs)\n",
    "\n",
    "Теоретическая основа: универсальная теорема аппроксимации - теорема Хорника-Цирельсона-Уайта: \\\n",
    "Однослойная нейроная сеть с достаточно большим числом нейронов и нелинейной гладкой функцией \\\n",
    "(например, sigmoid или tanh) может приблизить любую непрерывную функцию на компактном множестве \\\n",
    "с любой заданной точностью. \n",
    "\n",
    "$$\n",
    "sup_{x \\in K}| f(x) - N(x) | < \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0bfc7-18fc-4b56-8e59-37cba3dcd992",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Уравнение теплопроводности\n",
    "\n",
    "$$ \\frac{\\partial u(x,t)}{\\partial t}=\\frac{\\partial}{\\partial x}(k(x)*\\frac{\\partial u(x,t)}{\\partial x})+f(x,t)) $$\n",
    "$$ x \\in (0,L), \\, t \\in (0,T] $$ \\\n",
    "$ u(x,t) $ - температура  \\\n",
    "$ k(x) $ - коэф.теплопроводности \\\n",
    "$ f(x,t) $ - источники \\\\ стоки\n",
    "### Начальные условия:\n",
    "$$ u(x,0)=g_{IC}(x) $$\n",
    "$$ x \\in [0,L], \\, t = 0 $$\n",
    "### Граничные условия (например, первого рода):\n",
    "$$ u(0,t)=g_{LB}(t), u(L,t)=g_{RB}(t) $$\n",
    "$$ x \\in \\{0,L\\}, \\, t \\in (0,T] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ae47f-ef7b-4e7b-9b07-5a7d6f99e630",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Аппроксимация дифференциального уравнения нейроной сетью\n",
    "$ N_u(x,t) $ - нейросеть аппроксимирует u(x,t),тогда аппроксимированное ур-ие теплопроводности примет вид:\n",
    "$$\n",
    "\\frac{\\partial N_u(x,t)}{\\partial t}=\\frac{\\partial}{\\partial x}(k(x) \\frac{\\partial N_u(x,t)}{\\partial x})+f(x,t))\n",
    "$$\n",
    "\n",
    "или раскроем производную произведения и перенесем все в левую сторону\n",
    "$$\n",
    "\\frac{\\partial N_u(x,t)}{\\partial t} - \\frac{\\partial k(x)}{\\partial x} \\frac{\\partial N_u(x,t)}{\\partial x} - k(x) \\frac{\\partial^2 N_u(x,t)}{\\partial x^2} -f(x,t)) = 0\n",
    "$$\n",
    "\n",
    "Производная нейросети $ N_u(x,t) $, состоящая, например, из входа -> два внутренних слоя -> выход - \n",
    "это гладкая функция как композиция слоев нейросети \\\n",
    "$$ N_u(x,t) = f_3(f_2(f_1(x,t,\\theta), \\theta), \\theta), $$ \\\n",
    "$ f_1, f_2, f_3 $ - слои нейросети (линейные преобразования + функции активации) \\\n",
    "$ \\theta_i $ - обучаемые параметры (веса и смещения) \\\n",
    "производная $  N_u(x,t) $ вычисляется по цепному правилу:\n",
    "$$\n",
    "\\frac{\\partial N_u}{\\partial x} = \\frac{\\partial f_3}{\\partial f_2} * \\frac{\\partial f_2}{\\partial f_1} * \\frac{\\partial f_1}{\\partial x}\n",
    "$$\n",
    "где каждый член это якобиан (матрица частных производных)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb32d2a-6e34-4abd-8f53-2740e7ab5440",
   "metadata": {},
   "source": [
    "# Функция потерь (loss function)\n",
    "### 1. Partial Differential Equation loss: ошибка аппроксимации дифф.ур-ия нейронной сетью\n",
    "$$\n",
    "L_{PDE} = \\frac{1}{M} \\sum_{j=1}^M || \\frac{\\partial N_u(x,t)}{\\partial t} - \\frac{\\partial k(x)}{\\partial x} \\frac{\\partial N_u(x,t)}{\\partial x} - k(x) \\frac{\\partial^2 N_u(x,t)}{\\partial x^2} -f(x,t) ||^2\n",
    "$$\n",
    "$$ x \\in (0,L), t \\in (0,T] $$\n",
    "### 2. Initial condition loss: ошибка нейронной сети по начальным условиям\n",
    "$$ L_{IC} = \\frac{1}{K} \\sum_{j=1}^K || N_u(x,0) - g_{IC}(x) ||^2 $$\n",
    "$$ x \\in [0;L], t = 0 $$\n",
    "### 3. Boundary condition loss: ошибка нейронной сети по граничным условиям\n",
    "$$ L_{BC} = \\frac{1}{P} (\\sum_{j=1}^P || N_u(0,t) - g_{LB}(t) ||^2 + \\sum_{j=1}^P || N_u(L,t) - g_{RB}(t) ||^2) $$\n",
    "$$ x \\in \\{0,L\\}, t \\in (0,T] $$\n",
    "### 4. Data loss: ошибка предсказанных и экспериментальных данных\n",
    "$$ L_{data} = \\frac{1}{N} \\sum_{j=1}^N || N_u(x,t) - u_{data}(x,t) ||^2 $$\n",
    "$$ x \\in (0,L), t \\in (0,T] $$\n",
    "### Итоговый лосс:\n",
    "$$ L = \\lambda_{PDE} L_{PDE} + \\lambda_{IC} L_{IC} + \\lambda_{BC} L_{BC} + \\lambda_{data} L_{data} $$\n",
    "пояснение по выбору M,K,P,N пусть \n",
    "K - число пропорциональное кол-ву шагов дискретизации по времени, \n",
    "P - число пропорциональное кол-ву шагов дискретизации по пространству (в данном случае одномерному)\n",
    "тогда \n",
    "M - будет числом пропорциональным K*P кол-ву шагов дискретизации внутренней области определения\n",
    "N - кол-во возможных экспериментальных данных, которые попадают во внутреннюю область \\\n",
    "Таким образом:\n",
    "1. Решаем ПРЯМУЮ ЗАДАЧУ - на выходе получаем PINN физической модели (аппроксимацию дифференциального уравнения в частных производных с учетом нач. и гр. условий)\n",
    "$$ L_{phys} = \\lambda_{PDE} L_{PDE} + \\lambda_{IC} L_{IC} + \\lambda_{BC} L_{BC} $$\n",
    "3. Решаем ОБРАТНУЮ ЗАДАЧУ - дополнительно к аппроксимации физической модели $ N_u(x,t) $ добавляем в уравнение аппроксимацию, например, коэффициента теплопроводности $ N_k(x) $ и решаем задачу оптимизации двух PINN сетей  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef0923-b2bc-46b2-9468-0dd0a2b254e5",
   "metadata": {},
   "source": [
    "Пояснение по виду лоссов: $ loss = \\frac{1}{N} \\sum_{j=1}^N ||x||^2  $, где ||*|| - Евклидова норма. \\\n",
    "Если x - вектор независимых параметров, т.е. $ x \\in \\{x_1, x_2, ..., x_n\\} $\n",
    "то $ ||x|| = \\sqrt {x_1^2 + x_2^2 + ... x_n^2} $ (длина n-мерного вектора)  или $ ||x||^2 = \\sum_{i=1}^n x_i^2 $, тогда:\n",
    "$ loss =  \\frac{1}{N} \\sum_{j=1}^N (\\sum_{i=1}^n x_i^2) $, где первая сумма (справа) - длина n-мерного вектора в квадрате,\n",
    "а вторая сумма (слева) - среднее значение N длин в квадрате n-мерных векторов \\\n",
    "Если x - это скаляр, тогда: $ loss = \\frac{1}{N} \\sum_{j=1}^N (x^2) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439210de-c544-419e-80c6-99204b2d919e",
   "metadata": {},
   "source": [
    "# ПРИМЕР\n",
    "## 1. ПРЯМАЯ ЗАДАЧА\n",
    "### Пусть исходные данные следующие:\n",
    "$$ x \\in [0,1], \\, t \\in [0,1] $$\n",
    "$$ u(0,t) = u(L,t)=0 $$\n",
    "$$ u(x,0) = sin(\\pi * x) $$\n",
    "$$ k(x) = k_a \\, cos(2 \\pi x) + k_b $$ \n",
    "$$ \\frac{\\partial k(x)}{\\partial x} = - k_a 2 \\pi \\, sin(2 \\pi x) $$\n",
    "$$ f(x,t) = 0 $$\n",
    "Значения $ k_a $ и $ k_b $ такие, что $ k(x) $ положителен на всем интервале x тогда:\n",
    "### Partial Differential Equation loss:\n",
    "$$\n",
    "L_{PDE} = \\frac{1}{M} \\sum_{j=1}^M || \\frac{\\partial N_u(x,t)}{\\partial t} + k_a 2 \\pi \\, sin(2 \\pi x)*\\frac{\\partial N_u(x,t)}{\\partial x} - (k_a \\, cos(2 \\pi x) + k_b) *\\frac{\\partial^2 N_u(x,t)}{\\partial x^2} ||^2\n",
    "$$ \n",
    "$$ x \\in (0;L), t \\in (0;T] $$\n",
    "### Initial condition loss:\n",
    "$$ L_{IC} = \\frac{1}{K} \\sum_{j=1}^K || N_u(x,0) - sin(\\pi * x) ||^2 $$\n",
    "$$ x \\in [0;L], t = 0 $$\n",
    "### Boundary condition loss:\n",
    "$$ L_{BC} = \\frac{1}{P} (\\sum_{j=1}^P || N_u(0,t) ||^2 + \\sum_{j=1}^P || N_u(L,t) ||^2) $$\n",
    "$$ x=\\{0,L\\}, t \\in (0;T] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530f509-3f15-4a3d-9bae-797cfe25ea1d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 1.1 Создаем PDE нейроную сеть\n",
    "### 2 (вход) -> 5 (1-ый внутр.слой) -> 5 (2-ой внутр.слой) -> 1 (выход)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1400555e-e269-4529-ba74-bd61586d0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем нейросеть 2->5->5->1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Nu( nn.Module ):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2,5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5,5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(5,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.fc( torch.cat([x, t], dim=1) ) # self.layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c315ad1d-bb6e-4542-b529-419f5bd05e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nu(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (3): Sigmoid()\n",
       "    (4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net = Nu()\n",
    "u_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0357a30b-c37f-46d1-9940-6f7202b998b7",
   "metadata": {},
   "source": [
    "# 1.2 Проверка работы нейросети (вручную проходим от входа на выход по всем слоям)\n",
    "### 1.2.1 2 нейрона (вход) -> 5 нейронов (1-ый внутр.слой)\n",
    "$$\n",
    "h_i = Sigmoid(\\sum_{j=1}^2 w_{ij}x_j + b_i), i = 1,2,3,4,5\n",
    "$$\n",
    "\n",
    "или в матричном кратком виде: $ h = Sigmoid(W*x+b) $, или в матричном полном виде:\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "h_1 \\\\\n",
    "h_2 \\\\\n",
    "h_3 \\\\\n",
    "h_4 \\\\\n",
    "h_5\n",
    "\\end{vmatrix} \\quad = \\quad\n",
    "Sigmoid\n",
    "\\begin{pmatrix}\n",
    "\\begin{vmatrix}\n",
    "w_{11} & w_{12} \\\\\n",
    "w_{21} & w_{22} \\\\\n",
    "w_{31} & w_{32} \\\\\n",
    "w_{41} & w_{42} \\\\\n",
    "w_{51} & w_{52}\n",
    "\\end{vmatrix} *\n",
    "\\begin{vmatrix}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{vmatrix} \\quad + \\quad\n",
    "\\begin{vmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "b_3 \\\\\n",
    "b_4 \\\\\n",
    "b_5\n",
    "\\end{vmatrix}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a124f725-7fef-439d-b570-8a853a501c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.2000]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = torch.tensor([0.1, 0.2]).view(-1,1)\n",
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59e928a0-341e-477c-b160-0780c511a2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2971, -0.1073],\n",
      "        [ 0.4041, -0.2996],\n",
      "        [ 0.2805,  0.5935],\n",
      "        [ 0.4604,  0.0734],\n",
      "        [ 0.3943, -0.4974]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3398,  0.2451, -0.2366, -0.5725, -0.1150], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 2-> 5\n",
    "print(u_net.fc[0].weight)\n",
    "print(u_net.fc[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f9d897e-0155-4e36-942d-b3cfe6c99c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5862],\n",
       "        [0.5562],\n",
       "        [0.4776],\n",
       "        [0.3748],\n",
       "        [0.4564]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h = Sigmoid( W(1)x+b(1) )\n",
    "h = torch.sigmoid( u_net.fc[0].weight @ xt + u_net.fc[0].bias.view(-1,1) )\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016ae05-5944-438b-805a-86e530446006",
   "metadata": {},
   "source": [
    "### 1.2.2 5 нейронов (1-ый внутр.слой) -> 5 нейронов (2-ый внутр.слой)\n",
    "$$\n",
    "g_i = Sigmoid(\\sum_{j=1}^5 w_{ij}h_j + b_i), i = 1,2,3,4,5\n",
    "$$\n",
    "\n",
    "или в матричном кратком виде: $ g = Sigmoid(W*h+b) $, или в матричном полном виде:\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "g_1 \\\\\n",
    "g_2 \\\\\n",
    "g_3 \\\\\n",
    "g_4 \\\\\n",
    "g_5\n",
    "\\end{vmatrix} \\quad = \\quad\n",
    "Sigmoid\n",
    "\\begin{pmatrix}\n",
    "\\begin{vmatrix}\n",
    "w_{11} & w_{12} & w_{13} & w_{14} & w_{15} \\\\\n",
    "w_{21} & w_{22} & w_{23} & w_{24} & w_{25} \\\\\n",
    "w_{31} & w_{32} & w_{33} & w_{34} & w_{35} \\\\\n",
    "w_{41} & w_{42} & w_{43} & w_{44} & w_{45} \\\\\n",
    "w_{51} & w_{52} & w_{53} & w_{54} & w_{55} \n",
    "\\end{vmatrix} *\n",
    "\\begin{vmatrix}\n",
    "h_1 \\\\\n",
    "h_2 \\\\\n",
    "h_3 \\\\\n",
    "h_4 \\\\\n",
    "h_5\n",
    "\\end{vmatrix} \\quad + \\quad\n",
    "\\begin{vmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "b_3 \\\\\n",
    "b_4 \\\\\n",
    "b_5\n",
    "\\end{vmatrix}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "531df2ed-c8ea-4cf6-9e2c-ba50ed65f3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3868, -0.0568, -0.0261,  0.2307,  0.1421],\n",
      "        [ 0.1288, -0.1486, -0.4219, -0.2583, -0.4213],\n",
      "        [-0.4125,  0.2083,  0.1472, -0.2239, -0.2070],\n",
      "        [ 0.1134,  0.2205, -0.1971, -0.3777, -0.1586],\n",
      "        [ 0.1446,  0.4001, -0.1700, -0.3297, -0.2827]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3862, -0.3407, -0.1419, -0.3057,  0.2879], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 5-> 5\n",
    "print(u_net.fc[2].weight)\n",
    "print(u_net.fc[2].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "064fbc0d-b338-426d-a6b8-c35ea635bc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3762],\n",
       "        [0.3019],\n",
       "        [0.4071],\n",
       "        [0.3954],\n",
       "        [0.5650]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g = Sigmoid( W(2)h+b(2) )\n",
    "g = torch.sigmoid( u_net.fc[2].weight @ h + u_net.fc[2].bias.view(-1,1) )\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a980c-b802-43f4-9565-60cd23f43467",
   "metadata": {},
   "source": [
    "### 1.2.3 5 нейронов (2-ый внутр.слой) -> 1 нейрон (выход)\n",
    "$$\n",
    "y_i = \\sum_{j=1}^5 w_{ij}g_j + b_i, i = 1\n",
    "$$\n",
    "\n",
    "или в матричном кратком виде: $ y = W*g+b $, или в матричном полном виде:\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "y_1\n",
    "\\end{vmatrix} \\quad = \\quad\n",
    "\\begin{vmatrix}\n",
    "w_{11} & w_{12} & w_{13} & w_{14} & w_{15} \\\\\n",
    "\\end{vmatrix} *\n",
    "\\begin{vmatrix}\n",
    "g_1 \\\\\n",
    "g_2 \\\\\n",
    "g_3 \\\\\n",
    "g_4 \\\\\n",
    "g_5\n",
    "\\end{vmatrix} \\quad + \\quad\n",
    "\\begin{vmatrix}\n",
    "b_1\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "Обратите внимание, что функции активации нет, но могла бы быть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f2edd52-981f-454a-9946-a696514d0ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3285, -0.2794, -0.0612, -0.3419, -0.0533]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4354], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 5 -> 1\n",
    "print(u_net.fc[4].weight)\n",
    "print(u_net.fc[4].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9f51531-2720-4965-a351-2960919620f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5864]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = W(3)g+b(3)\n",
    "y = u_net.fc[4].weight @ g + u_net.fc[4].bias.view(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94d001-7036-42db-8e5a-950c88e9539c",
   "metadata": {},
   "source": [
    "# 1.3 Проверка ручных вычислений с автоматическим (передачей параметров в нейроную сеть)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e9236b81-59f9-4edb-8fdb-717b29ea9bb9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5864]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# придется входные данные представить немного в ином виде, т.к. в модели нейронки Nu параметры передаются\n",
    "# в пакетном batch режиме\n",
    "x_batch = xt[0].view(-1,1)\n",
    "t_batch = xt[1].view(-1,1)\n",
    "print(torch.cat([x_batch,t_batch], dim=1))\n",
    "# предсказания, на данном этапе нейронка инициализируется каким-то начальными значениями, \n",
    "# соответсвенно предсказание носит некий случайный характер в начале\n",
    "u_pred = u_net(x_batch,t_batch)\n",
    "u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6996b80-5642-444f-9231-93856d75fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if y == u_pred:\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a077f-4f7e-4e66-a1f5-e06f7e83575d",
   "metadata": {},
   "source": [
    "# 1.4 Задаем области определения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec53b7-c5cd-4a11-a9cb-c6995eb28a08",
   "metadata": {},
   "source": [
    "Пусть вся область будет 10х10, из них:\n",
    "1. внутрення область - 8х9 = 72\n",
    "2. начальные условия - 10х1 = 10\n",
    "3. граничные условия - 9х1х2 = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1785e5-d230-461b-b2c6-e472adbd2b74",
   "metadata": {},
   "source": [
    "### $ x \\in (0,1) \\, , t \\in (0,1] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6898a1c5-5635-4d73-bb3c-8898cc3fcf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.linspace(0,1,10)[1:9]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f12af9f8-23b7-49bd-9836-92aea5c6fc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.linspace(0,1,10)[1:9]\n",
    "x_batch_pde = torch.empty(0)\n",
    "\n",
    "for x in temp:\n",
    "    x_batch_pde = torch.cat( [x_batch_pde, x * torch.ones(9) ])\n",
    "x_batch_pde = x_batch_pde.view(-1,1)\n",
    "x_batch_pde.requires_grad = True\n",
    "x_batch_pde.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "142f040e-b2e3-45ff-ab63-3833c30905d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_batch_pde = torch.empty(0)\n",
    "\n",
    "for i in temp:\n",
    "    t_batch_pde = torch.cat( [ t_batch_pde, torch.linspace(0,1,10)[1:10] ] )\n",
    "t_batch_pde = t_batch_pde.view(-1,1)\n",
    "t_batch_pde.requires_grad = True\n",
    "t_batch_pde.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b26525b-e42e-413d-a973-0968dec87dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([72, 2])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat( [ x_batch_pde, t_batch_pde], dim=1 ).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026b1fe-78ad-4dd2-825d-0554d711430b",
   "metadata": {},
   "source": [
    "### $ x \\in [0,1] \\, , t=0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bcee84d-36a4-406e-9c99-a385325d77ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_ic = torch.linspace(0,1,10).view(-1,1)\n",
    "t_batch_ic = torch.zeros(10).view(-1,1)\n",
    "\n",
    "x_batch_ic.requires_grad = True\n",
    "t_batch_ic.requires_grad = True\n",
    "\n",
    "torch.cat([x_batch_ic, t_batch_ic], dim=1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726ee59-c60e-4def-b9e5-35895e8ed851",
   "metadata": {},
   "source": [
    "### $ x \\in \\{0,1\\} \\, , t \\in (0,1] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "93efde92-c456-423e-9349-025b52eb988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_bc = torch.cat( [torch.zeros(9).view(-1,1), torch.ones(9).view(-1,1)])\n",
    "t_batch_bc = torch.cat( [torch.linspace(0,1,10)[1:10].view(-1,1), torch.linspace(0,1,10)[1:10].view(-1,1)] )\n",
    "\n",
    "x_batch_bc.requires_grad = True\n",
    "t_batch_bc.requires_grad = True\n",
    "\n",
    "torch.cat([x_batch_bc, t_batch_bc], dim=1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c377a-6b8b-41ff-a51a-0a5852708a4b",
   "metadata": {},
   "source": [
    "### Полная область определения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f0bd0de0-5a3f-4862-b613-9caa3a757e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch = torch.cat([x_batch_pde, x_batch_ic, x_batch_bc])\n",
    "t_batch = torch.cat([t_batch_pde, t_batch_ic, t_batch_bc])\n",
    "\n",
    "torch.cat([x_batch, t_batch], dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0052955e-17f2-48a2-8655-0289a2bb8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net = Nu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6a49192b-da82-4586-9c28-8633655bbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam( u_net.parameters(), lr=1e-2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f25709-91d1-489f-9c9d-f6ea45a0d88f",
   "metadata": {},
   "source": [
    "# 1.5 Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2360e264-e07d-42ee-9ee2-4eacd355045e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10000], Loss: 0.39573, loss pde: 0.00000, loss ic: 0.13110, loss bc: 0.26463\n",
      "Epoch [20/10000], Loss: 0.28867, loss pde: 0.00002, loss ic: 0.19629, loss bc: 0.09236\n",
      "Epoch [40/10000], Loss: 0.28647, loss pde: 0.00012, loss ic: 0.21789, loss bc: 0.06845\n",
      "Epoch [60/10000], Loss: 0.28295, loss pde: 0.00047, loss ic: 0.20954, loss bc: 0.07295\n",
      "Epoch [80/10000], Loss: 0.27792, loss pde: 0.00180, loss ic: 0.20385, loss bc: 0.07227\n",
      "Epoch [100/10000], Loss: 0.27176, loss pde: 0.00637, loss ic: 0.19765, loss bc: 0.06774\n",
      "Epoch [120/10000], Loss: 0.26865, loss pde: 0.01439, loss ic: 0.19052, loss bc: 0.06374\n",
      "Epoch [140/10000], Loss: 0.26711, loss pde: 0.01646, loss ic: 0.18817, loss bc: 0.06247\n",
      "Epoch [160/10000], Loss: 0.26427, loss pde: 0.01520, loss ic: 0.18741, loss bc: 0.06166\n",
      "Epoch [180/10000], Loss: 0.25834, loss pde: 0.01507, loss ic: 0.18372, loss bc: 0.05955\n",
      "Epoch [200/10000], Loss: 0.24667, loss pde: 0.01423, loss ic: 0.17589, loss bc: 0.05654\n",
      "Epoch [220/10000], Loss: 0.22623, loss pde: 0.01164, loss ic: 0.16206, loss bc: 0.05253\n",
      "Epoch [240/10000], Loss: 0.18700, loss pde: 0.00449, loss ic: 0.13924, loss bc: 0.04328\n",
      "Epoch [260/10000], Loss: 0.13082, loss pde: 0.00011, loss ic: 0.09921, loss bc: 0.03150\n",
      "Epoch [280/10000], Loss: 0.08780, loss pde: 0.00002, loss ic: 0.06281, loss bc: 0.02498\n",
      "Epoch [300/10000], Loss: 0.05019, loss pde: 0.00001, loss ic: 0.03453, loss bc: 0.01565\n",
      "Epoch [320/10000], Loss: 0.02297, loss pde: 0.00017, loss ic: 0.01395, loss bc: 0.00885\n",
      "Epoch [340/10000], Loss: 0.00953, loss pde: 0.00000, loss ic: 0.00511, loss bc: 0.00443\n",
      "Epoch [360/10000], Loss: 0.00491, loss pde: 0.00001, loss ic: 0.00248, loss bc: 0.00241\n",
      "Epoch [380/10000], Loss: 0.00340, loss pde: 0.00004, loss ic: 0.00190, loss bc: 0.00146\n",
      "Epoch [400/10000], Loss: 0.00246, loss pde: 0.00000, loss ic: 0.00156, loss bc: 0.00089\n",
      "Epoch [420/10000], Loss: 0.00170, loss pde: 0.00001, loss ic: 0.00118, loss bc: 0.00050\n",
      "Epoch [440/10000], Loss: 0.00110, loss pde: 0.00000, loss ic: 0.00085, loss bc: 0.00025\n",
      "Epoch [460/10000], Loss: 0.00071, loss pde: 0.00000, loss ic: 0.00059, loss bc: 0.00012\n",
      "Epoch [480/10000], Loss: 0.00049, loss pde: 0.00000, loss ic: 0.00042, loss bc: 0.00007\n",
      "Epoch [500/10000], Loss: 0.00036, loss pde: 0.00000, loss ic: 0.00032, loss bc: 0.00004\n",
      "Epoch [520/10000], Loss: 0.00031, loss pde: 0.00001, loss ic: 0.00026, loss bc: 0.00003\n",
      "Epoch [540/10000], Loss: 0.00026, loss pde: 0.00000, loss ic: 0.00023, loss bc: 0.00003\n",
      "Epoch [560/10000], Loss: 0.00023, loss pde: 0.00000, loss ic: 0.00021, loss bc: 0.00003\n",
      "Epoch [580/10000], Loss: 0.00022, loss pde: 0.00000, loss ic: 0.00019, loss bc: 0.00003\n",
      "Epoch [600/10000], Loss: 0.00021, loss pde: 0.00000, loss ic: 0.00018, loss bc: 0.00003\n",
      "Epoch [620/10000], Loss: 0.00024, loss pde: 0.00004, loss ic: 0.00017, loss bc: 0.00003\n",
      "Epoch [640/10000], Loss: 0.00020, loss pde: 0.00000, loss ic: 0.00017, loss bc: 0.00003\n",
      "Epoch [660/10000], Loss: 0.00019, loss pde: 0.00000, loss ic: 0.00017, loss bc: 0.00003\n",
      "Epoch [680/10000], Loss: 0.00019, loss pde: 0.00000, loss ic: 0.00016, loss bc: 0.00003\n",
      "Epoch [700/10000], Loss: 0.00018, loss pde: 0.00000, loss ic: 0.00016, loss bc: 0.00003\n",
      "Epoch [720/10000], Loss: 0.00018, loss pde: 0.00000, loss ic: 0.00015, loss bc: 0.00003\n",
      "Epoch [740/10000], Loss: 0.00018, loss pde: 0.00000, loss ic: 0.00015, loss bc: 0.00003\n",
      "Epoch [760/10000], Loss: 0.00018, loss pde: 0.00001, loss ic: 0.00014, loss bc: 0.00003\n",
      "Epoch [780/10000], Loss: 0.00018, loss pde: 0.00001, loss ic: 0.00014, loss bc: 0.00003\n",
      "Epoch [800/10000], Loss: 0.00017, loss pde: 0.00000, loss ic: 0.00014, loss bc: 0.00003\n",
      "Epoch [820/10000], Loss: 0.00016, loss pde: 0.00000, loss ic: 0.00014, loss bc: 0.00002\n",
      "Epoch [840/10000], Loss: 0.00016, loss pde: 0.00000, loss ic: 0.00013, loss bc: 0.00002\n",
      "Epoch [860/10000], Loss: 0.00015, loss pde: 0.00000, loss ic: 0.00013, loss bc: 0.00002\n",
      "Epoch [880/10000], Loss: 0.00015, loss pde: 0.00000, loss ic: 0.00013, loss bc: 0.00002\n",
      "Epoch [900/10000], Loss: 0.00015, loss pde: 0.00000, loss ic: 0.00013, loss bc: 0.00002\n",
      "Epoch [920/10000], Loss: 0.00036, loss pde: 0.00020, loss ic: 0.00012, loss bc: 0.00004\n",
      "Epoch [940/10000], Loss: 0.00015, loss pde: 0.00001, loss ic: 0.00012, loss bc: 0.00002\n",
      "Epoch [960/10000], Loss: 0.00014, loss pde: 0.00000, loss ic: 0.00012, loss bc: 0.00002\n",
      "Epoch [980/10000], Loss: 0.00014, loss pde: 0.00000, loss ic: 0.00012, loss bc: 0.00002\n",
      "Epoch [1000/10000], Loss: 0.00013, loss pde: 0.00000, loss ic: 0.00011, loss bc: 0.00002\n",
      "Epoch [1020/10000], Loss: 0.00013, loss pde: 0.00000, loss ic: 0.00011, loss bc: 0.00002\n",
      "Epoch [1040/10000], Loss: 0.00013, loss pde: 0.00000, loss ic: 0.00011, loss bc: 0.00002\n",
      "Epoch [1060/10000], Loss: 0.00012, loss pde: 0.00000, loss ic: 0.00011, loss bc: 0.00002\n",
      "Epoch [1080/10000], Loss: 0.00012, loss pde: 0.00000, loss ic: 0.00010, loss bc: 0.00002\n",
      "Epoch [1100/10000], Loss: 0.00012, loss pde: 0.00001, loss ic: 0.00010, loss bc: 0.00002\n",
      "Epoch [1120/10000], Loss: 0.00012, loss pde: 0.00000, loss ic: 0.00010, loss bc: 0.00002\n",
      "Epoch [1140/10000], Loss: 0.00011, loss pde: 0.00000, loss ic: 0.00010, loss bc: 0.00002\n",
      "Epoch [1160/10000], Loss: 0.00011, loss pde: 0.00000, loss ic: 0.00009, loss bc: 0.00002\n",
      "Epoch [1180/10000], Loss: 0.00011, loss pde: 0.00000, loss ic: 0.00009, loss bc: 0.00002\n",
      "Epoch [1200/10000], Loss: 0.00010, loss pde: 0.00000, loss ic: 0.00009, loss bc: 0.00001\n",
      "Epoch [1220/10000], Loss: 0.00010, loss pde: 0.00000, loss ic: 0.00009, loss bc: 0.00001\n",
      "Epoch [1240/10000], Loss: 0.00010, loss pde: 0.00000, loss ic: 0.00009, loss bc: 0.00001\n",
      "stop optimization\n"
     ]
    }
   ],
   "source": [
    "# параметры для расчета loss_pde\n",
    "#ka, kb = 0.02, 0.1\n",
    "ka, kb = 0.00, 0.3\n",
    "# весовые коэффициенты для общего loss\n",
    "alpha_pde, alpha_ic, alpha_bc = 1.,1.,1.\n",
    "# обучение\n",
    "MAX = 10000\n",
    "for epoch in range(MAX):\n",
    "    # ---------------------------------- ПРЕДИКТИВНЫЕ ДАННЫЕ ПО ВСЕЙ ОБЛАСТИ ОПРЕДЕЛЕНИЯ ----------------\n",
    "    u_pred = u_net(x_batch,t_batch)\n",
    "    # ---------------------------------- LOSS PDE ----------------\n",
    "    u_pred_pde = u_pred[0:72]\n",
    "    # du/dx, du/dt\n",
    "    [du_dx, du_dt] = torch.autograd.grad(u_pred_pde, inputs=[x_batch_pde, t_batch_pde], grad_outputs=torch.ones_like(x_batch_pde), create_graph=True, retain_graph=True)\n",
    "    # d2u/dx2\n",
    "    [d2u_dx2, du_dxdt] = torch.autograd.grad(du_dx, inputs=[x_batch_pde, t_batch_pde], grad_outputs=torch.ones_like(x_batch_pde), create_graph=True, retain_graph=True)\n",
    "    # loss pde\n",
    "    loss_pde = torch.mean((du_dt[0] + ka*2*torch.pi*torch.sin(2*torch.pi*x_batch_pde)*du_dx[0] - (ka*torch.cos(2*torch.pi*x_batch_pde) +kb)*d2u_dx2[0])**2)\n",
    "    # ---------------------------------- LOSS IC -----------------\n",
    "    u_pred_ic = u_pred[72:82]\n",
    "    loss_ic = torch.mean( (u_pred_ic - torch.sin(torch.pi*x_batch_ic))**2 )\n",
    "    # ---------------------------------- LOSS BC -----------------\n",
    "    u_pred_bc = u_pred[82:100]\n",
    "    loss_bc = torch.mean( (u_pred_bc)**2 )\n",
    "    # ---------------------------------- LOSS COMMON -------------\n",
    "    loss = alpha_pde * loss_pde + alpha_ic * loss_ic + alpha_bc * loss_bc\n",
    "    # стираем предыдущий граф градиента\n",
    "    optimizer.zero_grad()\n",
    "    # обратное распространение ошибки\n",
    "    loss.backward()\n",
    "    # записываем новые коэфициента\n",
    "    optimizer.step()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch [{epoch}/{MAX}], Loss: {loss.item():.5f}, loss pde: {loss_pde.item():.5f}, loss ic: {loss_ic.item():.5f}, loss bc: {loss_bc.item():.5f}')\n",
    "    if loss < 0.0001:\n",
    "        print('stop optimization')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17c82c-24db-4aea-8edf-3fd3607d429b",
   "metadata": {},
   "source": [
    "# 1.7 Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "acfe54f2-6f69-4757-9f62-41a215f14890",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_res = u_net(x_batch,t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a08f8483-b43c-40f9-bd4f-156ca936ea15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0091],\n",
       "        [0.3231],\n",
       "        [0.6337],\n",
       "        [0.8671],\n",
       "        [0.9877],\n",
       "        [0.9904],\n",
       "        [0.8743],\n",
       "        [0.6426],\n",
       "        [0.3283],\n",
       "        [0.0062]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial condition\n",
    "u_res[72:82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8ce63d9d-a0e0-4b1d-915d-0100a98dc40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0079],\n",
       "        [ 0.0066],\n",
       "        [ 0.0053],\n",
       "        [ 0.0038],\n",
       "        [ 0.0022],\n",
       "        [ 0.0003],\n",
       "        [-0.0019],\n",
       "        [-0.0043],\n",
       "        [-0.0072],\n",
       "        [ 0.0036],\n",
       "        [ 0.0016],\n",
       "        [ 0.0001],\n",
       "        [-0.0008],\n",
       "        [-0.0013],\n",
       "        [-0.0012],\n",
       "        [-0.0007],\n",
       "        [ 0.0002],\n",
       "        [ 0.0015]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boundary condition\n",
    "u_res[82:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "794ebe82-045e-4152-9932-c112837d5466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3211, 0.3185, 0.3153, 0.3115, 0.3069, 0.3016, 0.2956, 0.2887, 0.2810],\n",
       "        [0.6323, 0.6296, 0.6258, 0.6207, 0.6144, 0.6068, 0.5978, 0.5876, 0.5760],\n",
       "        [0.8672, 0.8657, 0.8626, 0.8578, 0.8515, 0.8434, 0.8338, 0.8224, 0.8093],\n",
       "        [0.9891, 0.9886, 0.9864, 0.9823, 0.9764, 0.9686, 0.9590, 0.9475, 0.9342],\n",
       "        [0.9918, 0.9914, 0.9891, 0.9848, 0.9787, 0.9706, 0.9606, 0.9487, 0.9349],\n",
       "        [0.8744, 0.8727, 0.8692, 0.8639, 0.8569, 0.8481, 0.8375, 0.8252, 0.8111],\n",
       "        [0.6405, 0.6370, 0.6323, 0.6264, 0.6192, 0.6109, 0.6014, 0.5907, 0.5790],\n",
       "        [0.3248, 0.3210, 0.3169, 0.3125, 0.3078, 0.3028, 0.2976, 0.2922, 0.2865]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDE\n",
    "u_res[0:72].view(8,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
